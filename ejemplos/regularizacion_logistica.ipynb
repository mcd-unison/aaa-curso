{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://mcd.unison.mx/wp-content/themes/awaken/img/logo_mcd.png)\n",
    "\n",
    "# Ejemplo de regularización con regresión logística\n",
    "\n",
    "## Aprendizaje Automático Aplicado\n",
    "\n",
    "## Maestría en Ciencia de Datos\n",
    "\n",
    "**Julio Waissman**, 2025\n",
    "\n",
    "[Abrir en google Colab](https://colab.research.google.com/github/mcd-unison/aaa-curso/blob/main/ejemplos/regularizacion_logistica.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algunas funciones útiles\n",
    "\n",
    "Esto, antes de agregarle la regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medias_std(x):\n",
    "    \"\"\"\n",
    "    Obtiene un vector de medias y desviaciones estandar para normalizar\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.mean(x, axis=0), np.std(x, axis=0)\n",
    "\n",
    "def normaliza(x, mu, des_std):\n",
    "    \"\"\"\n",
    "    Normaliza los datos x\n",
    "        \n",
    "    \"\"\"\n",
    "    return (x - mu) / des_std\n",
    "\n",
    "def map_poly(grad, x):\n",
    "    \"\"\"\n",
    "    Encuentra las características polinomiales hasta el grado grad de la matriz de datos x, asumiendo que x[:n, 0] es la expansión de orden 1 (los valores de cada atributo)\n",
    "    \n",
    "    \"\"\"\n",
    "    if int(grad) < 2:\n",
    "        raise ValueError('grad debe de ser mayor a 1')\n",
    "    \n",
    "    M, n = x.shape\n",
    "    atrib = x.copy()\n",
    "    x_phi = x.copy()\n",
    "    for i in range(2, int(grad) + 1):\n",
    "        for comb in combinations_with_replacement(range(n), i):\n",
    "            x_phi = np.c_[x_phi, np.prod(atrib[:, comb], axis=1)]\n",
    "    return x_phi   \n",
    "\n",
    "def logistica(z):\n",
    "    \"\"\"\n",
    "    Calcula la función logística para cada elemento de z\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def error_in(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Calcula el error en muestra para la regresión logística\n",
    "    \n",
    "    \"\"\" \n",
    "    a = logistica(x @ w + b)\n",
    "    return -np.nansum(\n",
    "            np.sum(np.log(a[y > 0.5])) + \n",
    "            np.sum(np.log(1 - a[y < 0.5]))\n",
    "        ) / a.shape[0]\n",
    "\n",
    "def gradiente_error(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Calcula el gradiente de la función de error en muestra.\n",
    "                    \n",
    "    \"\"\"\n",
    "    M = x.shape[0]\n",
    "    error = y - logistica(x @ w + b)\n",
    "    dw = -x.T @ error / M\n",
    "    db = - error.mean()    \n",
    "    return dw, db\n",
    "\n",
    "def dg(x, y, w, b, alpha, max_iter=10_000, tol=1e-6, historial=False):\n",
    "    \"\"\"\n",
    "    Descenso de gradiente por lotes \n",
    "             \n",
    "    \"\"\"\n",
    "    M, n = x.shape    \n",
    "    hist = [error_in(x, y, w, b)] if historial else None\n",
    "    for epoch in range(1, max_iter):\n",
    "        dw, db = gradiente_error(x, y, w, b)\n",
    "        w -= alpha * dw\n",
    "        b -= alpha * db\n",
    "        error = error_in(x, y, w, b)\n",
    "        if historial:\n",
    "            hist.append(error)\n",
    "        if np.abs(np.max(dw)) < tol:\n",
    "            break \n",
    "    return w, b, hist\n",
    "\n",
    "def predictor(x, w, b):\n",
    "    \"\"\"\n",
    "    Predice la clase de cada elemento de x\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.where(x @ w + b > 0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regularización\n",
    "\n",
    "Tomemos una base de datos que si bien es sintética es representativa de una familia de problemas a resolver. Supongamos que estámos opimizando la fase de pruebas dentro de la linea de producción de la empresa Microprocesadores del Noroeste S.A. de C.V.. La idea es reducir el banco de pruebas de cada nuevo microprocesador fabricado y en lugar de hacer 50 pruebas, reducirlas a 2. En el conjunto de datos tenemos los valores que obtuvo cada componente en las dos pruebas seleccionadas, y la decisión que se tomo con cada dispositivo (esta desición se tomo con el banco de 50 reglas). Los datos los podemos visualizar a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/mcd-unison/aaa-curso/raw/main/ejemplos/prod_test.csv\"\n",
    "datos = np.loadtxt(url, comments='%', delimiter=',')\n",
    "\n",
    "x, y = datos[:,0:-1], datos[:,-1] \n",
    "\n",
    "plt.plot(x[y == 1, 0], x[y == 1, 1], 'or', label='cumple calidad') \n",
    "plt.plot(x[y == 0, 0], x[y == 0, 1], 'ob', label='rechazado')\n",
    "plt.title(u'Ejemplo de pruebas de un producto')\n",
    "plt.xlabel(u'Valor obtenido en prueba 1')\n",
    "plt.ylabel(u'Valor obtenido en prueba 2')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cláramente este problema no se puede solucionar con un clasificador lineal (1 orden), por lo que hay que probar otros tipos de clasificadores.\n",
    "\n",
    "**Completa el código para hacer regresión polinomial para polinomios de orden 2, 4, 6 y 8, y muestra los resultados en una figura. Recuerda que este ejercicio puede tomar bastante tiempo de cómputo. Posiblemente tengas que hacer ajustes en el código para manejar diferentes valores de alpha y max_iter de acuerdo a cada caso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, grado) in enumerate([2, 6, 10, 14]):\n",
    "\n",
    "    # Genera la expansión polinomial\n",
    "    # --- Agregar código aquí ---\n",
    "    \n",
    "    \n",
    "    # Normaliza\n",
    "    # --- Agregar código aquí ---\n",
    "\n",
    "    \n",
    "    # Entrena\n",
    "    # --- Agregar código aquí ---\n",
    " \n",
    "\n",
    "\n",
    "    # Muestra resultados con plot_separacion2D \n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.title(f\"Polinomio de grado {grado}\")\n",
    "    # --- Agregar codigo aquí ---\n",
    "    # plot_separacion2D(...) Esto es solo para ayudarlos un poco\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver del ejercicio anterior, es dificil determinar el grado del polinomio, y en algunos casos es demasiado general (subaprendizaje) y en otros demasiado específico (sobreaprendizaje). \n",
    "\n",
    "¿Que podría ser la solución?, Una solución posible es utilizar un polinomio de alto grado (o relativamente alto), y utilizar la **regularización** para controlar la generalización del algoritmo, a través de una variable $\\lambda$.\n",
    "\n",
    "Recordemos, la función de costos de la regresión logística con regularización es:\n",
    "\n",
    "$$\n",
    "costo(w, b) = E_{in}(w, b) + \\frac{\\lambda}{M} regu(w),\n",
    "$$\n",
    "\n",
    "donde $regu(w)$ es una función de regularización, la cual puede ser $l_1$, $l_2$ u otras, tal como vimos en clase. \n",
    "\n",
    "**Completa el siguiente código, utilizando una regularización en $L_2$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costo(x, y, w, b, lambd):\n",
    "    \"\"\"\n",
    "    Calcula el costo de una w dada para el conjunto dee entrenamiento dado por y y x,\n",
    "    usando regularización\n",
    "    \n",
    "    @param x: un ndarray de dimensión (M, n) con la matriz de diseño\n",
    "    @param y: un ndarray de dimensión (M, ) donde cada entrada es 1.0 o 0.0\n",
    "    @param w: un ndarray de dimensión (n, ) con los pesos\n",
    "    @param b: un flotante con el sesgo\n",
    "    @param lambd: un flotante con el valor de lambda en la regularizacion\n",
    "\n",
    "    @return: un flotante con el valor de pérdida\n",
    "    \n",
    "    \"\"\" \n",
    "    costo = 0\n",
    "    M = x.shape[0]\n",
    "    \n",
    "    #------------------------------------------------------------------------\n",
    "    # Agregua aqui tu código\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------------\n",
    "    return costo\n",
    "\n",
    "\n",
    "def grad_regu(x, y, w, b, lambd):\n",
    "    \"\"\"\n",
    "    Calcula el gradiente de la función de costo regularizado para clasificación binaria, \n",
    "    utilizando una neurona logística, para w y b y conociendo un conjunto de aprendizaje.\n",
    "    \n",
    "    @param x: un ndarray de dimensión (M, n) con la matriz de diseño\n",
    "    @param y: un ndarray de dimensión (M, ) donde cada entrada es 1.0 o 0.0\n",
    "    @param w: un ndarray de dimensión (n, ) con los pesos\n",
    "    @param b: un flotante con el sesgo\n",
    "    @param lambd: un flotante con el peso de la regularización\n",
    "    \n",
    "    @return: dw, db, un ndarray de mismas dimensiones que w y un flotnte con el cálculo de \n",
    "             la dervada evluada en el punto w y b\n",
    "                 \n",
    "    \"\"\"\n",
    "    M = x.shape[0]\n",
    "    dw = np.zeros_like(w)\n",
    "    db = 0.0\n",
    "\n",
    "    #------------------------------------------------------------------------\n",
    "    # Agregua aqui tu código\n",
    "\n",
    "    \n",
    "    #------------------------------------------------------------------------\n",
    "    return dw, db\n",
    "\n",
    "\n",
    "def dg_regu(x, y, w, b, alpha, lambd, max_iter=10_000, tol=1e-4, historial=False):\n",
    "    \"\"\"\n",
    "    Descenso de gradiente con regularización l2\n",
    "\n",
    "    @param x: un ndarray de dimensión (M, n) con la matriz de diseño\n",
    "    @param y: un ndarray de dimensión (M, ) donde cada entrada es 1.0 o 0.0\n",
    "    @param alpha: Un flotante (típicamente pequeño) con la tasa de aprendizaje\n",
    "    @param lambd: Un flotante con el valor de la regularización\n",
    "    @param max_iter: Máximo numero de iteraciones. Por default 10_000\n",
    "    @param tol: Un flotante pequeño como criterio de paro. Por default 1e-4\n",
    "    @param historial: Un booleano para saber si guardamos el historial\n",
    "    \n",
    "    @return: \n",
    "        - w: ndarray de dimensión (n, ) con los pesos; \n",
    "        - b:  float con el sesgo \n",
    "        - hist: ndarray de (max_iter,) el historial de error. \n",
    "                Si historial == False, entonces hist = None.\n",
    "             \n",
    "    \"\"\"\n",
    "    M, n = x.shape    \n",
    "    hist = [costo(x, y, w, b, lambd)] if historial else None\n",
    "    for epoch in range(1, max_iter):\n",
    "        dw, db = grad_regu(x, y, w, b, lambd)\n",
    "        w -= alpha * dw\n",
    "        b -= alpha * db\n",
    "        error = costo(x, y, w, b, lambd)\n",
    "        if historial:\n",
    "            hist.append(error)\n",
    "        if np.abs(np.max(dw)) < tol:\n",
    "            break \n",
    "    return w, b, hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Desarrolla las funciones y scripts necesarios para realizar la regresión logística con un polinomio de grado `grado` y con cuatro valores de regularización diferentes. Grafica la superficie de separación para cuatro valores diferentes de $\\lambda$.**\n",
    "\n",
    "Realiza varias pruebas para encontrar cual es la relación de `grado` y de $\\lambda$ que sea un buen compromiso entre generalizar demasiado o tener sobreaprendizaje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grado = 5\n",
    "phi_x = map_poly(grado, x)\n",
    "mu, de = medias_std(phi_x)\n",
    "phi_x_norm = normaliza(phi_x, mu, de)\n",
    "\n",
    "\n",
    "for (i, lambd) in enumerate([0, 1, 10, 100]):\n",
    "\n",
    "    # Normaliza\n",
    "    # --- Agregar código aquí ---\n",
    "    \n",
    "    # Entrena\n",
    "    # --- Agregar código aquí ---\n",
    "    \n",
    "    # Muestra resultados con plot_separacion2D \n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.title(f\"Polinomio de grado {grado}, regu = {lambd}.\")\n",
    "    # --- Agregar codigo aquí ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy importante el análisis y las conclusiones que puedas sacar de este ejercicio.\n",
    "\n",
    "**Escribe aquí tus conclusiones**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
