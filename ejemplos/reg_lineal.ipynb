{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://mcd.unison.mx/wp-content/themes/awaken/img/logo_mcd.png)\n",
    "\n",
    "# Ejemplo de Regresión lineal\n",
    "\n",
    "## Aprendizaje Automático Aplicado\n",
    "\n",
    "## Maestría en Ciencia de Datos\n",
    "\n",
    "**Julio Waissman**, 2025\n",
    "\n",
    "[Abrir en google Colab](https://colab.research.google.com/github/mcd-unison/aaa-curso/blob/main/ejemplos/reg_lineal.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16,8)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Un ejemplo en una sola dimensión\n",
    "\n",
    "Vamos a abrir y a visualizar unos datos que se encuentran en el archivo `carretas.txt` (abrelos con un editor de texto si quieres ver el archivo original). En este archivo se tiene las ganancias anuales (en dolares) de unos tacos de carreta (bueno, su equivalente gringo) respecto al tamaño de la ciudad donde se encuentra la carreta. Estos datos provienen de el curso de *Machine learning* de *coursera* de *Andrew Ng*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee los datos en un nd array llamado datos\n",
    "\n",
    "url = 'https://github.com/mcd-unison/aaa-curso/raw/main/ejemplos/carretas.txt'\n",
    "datos = np.loadtxt(url, comments='%', delimiter=',')\n",
    "\n",
    "# Separa los datos de entrada de los de salida.\n",
    "# si decimos que x = datos[:,0], pues se toma solo una columna de datos,\n",
    "# por lo que x sería un ndarray de forma (shape) (96,). Al decir x = datos[:, 0:1] \n",
    "# significa que vamos a tomar todas las columnas de 0 a una antes de 1, por lo\n",
    "# que x tiene una forma (96, 1). Para mantener generalidad, es mejor manejar x como una matriz\n",
    "# de una sola columna que como un vector de una dimensión.\n",
    "x, y = datos[:,0:1], datos[:,1]\n",
    "\n",
    "# T es el número de instancias y n el de atributos\n",
    "T, n = x.shape\n",
    "\n",
    "plt.plot(x, y, 'rx')\n",
    "plt.title(u'Ganancias anuales de una carreta de acuerdo al tamaño de una ciudad')\n",
    "plt.xlabel(r\"Poblaci$\\'o$n ($\\times 10^4$ habitantes)\")\n",
    "plt.ylabel(r'Beneficios ($\\times 10^4$ dolares)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, ya temos los datos. La hipótesis que hacemos es que el valor de salida lo podemos estimar como\n",
    "\n",
    "$$\n",
    "\\hat{y}^{(i)} = h_{\\theta}(x^{(i)}) = \\omega_1 x^{(i)} + b, \\quad \\theta = (b, \\omega_1)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El criterio MSE como función de pérdida es el de minimizar el costo definido como\n",
    "$$\n",
    "E_{in}(\\omega, b) = \\frac{1}{2M} \\sum_{i = 1}^M (y^{(i)} - \\hat{y}^{(i)})^2.\n",
    "$$\n",
    "\n",
    "Por lo tanto, para saber si estamos minimizando o no, debemos ser capaces de medir la función de pérdida. \n",
    "\n",
    "**Desarrolla la función de costo tal como se pide abajo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Calcula el costo de acuerdo al criterio de MSE (mean square error) asumiendo un conjunto de datos\n",
    "    x, con una salida y, y una hipótesis lineal parametrizada por omega\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    x: Un ndarray de dimension (M, n)\n",
    "    y: Un ndarray de dimensión (M, )\n",
    "    w: Un ndarray de dimensión (n, )\n",
    "    b: Un flotante\n",
    "    \n",
    "    Devuelve\n",
    "    --------\n",
    "    Un flotante con el costo\n",
    "    \n",
    "    \"\"\"\n",
    "    M, n = x.shape\n",
    "    loss = 0\n",
    "        \n",
    "    # Puedes hacerlo en forma de ciclos\n",
    "    # J = 0\n",
    "    # for instancia in range(M):\n",
    "    #    J += --inserta aqui tu código--\n",
    "    # loss = --inserta aquí tu código--\n",
    "    \n",
    "    # Puedes hacerlo directamente usando numpy \n",
    "    # loss = --aqui se inserta código--\n",
    "\n",
    "    return loss\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y para probar si está bien el programa, si calculamos $E_in(\\omega, b)$ para $\\omega_1 = 0$, $b = 1$ debe de dar (para este conjunto de datos) **26.73** (recuerda verificar que regrese un flotante y no un vector de un solo elemento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros([n])\n",
    "b = 1\n",
    "print(\"El error en muestra es {}\".format(mse(x, y, w, b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muy bien, ya podemos calcular el criterio a optimizar. Vamos entonces a utilizar la función que acabamos de hacer para ver sus valores para diferentes valores de $\\omega$ y $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función de burrito (wrap) que depende solo de b y theta1\n",
    "def costo_w(b, w1):\n",
    "    return mse(x, y, np.array([w1]), b)\n",
    "\n",
    "# Y ahora la convertimos en una función tipo numpy (aplica para cualquier entrada de ndarrays)\n",
    "costo_vect = np.frompyfunc(costo_w, 2, 1)\n",
    "\n",
    "#Ahora generamos la lista de valores para graficar\n",
    "b = np.linspace(-15, 10, 100);\n",
    "w1 = np.linspace(-2, 4, 100);\n",
    "\n",
    "# Y los convertimos en matrices utilizando la función meshgrid\n",
    "b, w1 = np.meshgrid(b, w1)\n",
    "\n",
    "# Y calculamos los costos para cada par de theta0 y theta 1 con nuestra nueva funcion de costos vectorizada\n",
    "J = costo_vect(b, w1)\n",
    "\n",
    "# Y graficamos el contorno\n",
    "plt.contour(b, w1, J, 80, linewidths=0.5, colors='k')\n",
    "plt.contourf(b, w1, J, 80, cmap=plt.cm.rainbow, vmax=J.max(), vmin=J.min())\n",
    "plt.colorbar()\n",
    "plt.xlabel(r\"$b$\")\n",
    "plt.ylabel(r\"$\\omega_1$\")\n",
    "plt.title(r\"Funcion de perdida\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si, ya tenemos todo para hacer nuestra función para encontrar los parámetros que optimicen la función de costo (que como se puede ver en la superficie debería de estar por donde $b$ vale entre 0 y -5 y $\\omega_1$ entre 1 y 2). \n",
    "\n",
    "**Desarrolla la función con descenso de gradiente.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_costo(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Calcula el gradiente respecto a w y b de los datos existentes\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    x: ndarray de dimension [M, n] con la matriz de diseño\n",
    "    y: ndarray de dimension [M,] con los valores de salida\n",
    "    w: ndarray de dimension [n, ] con los pesos \n",
    "    b: flotante con el sesgo \n",
    "    \n",
    "    Devuelve\n",
    "    --------\n",
    "    dw, db: donde dw es un vector de dimension de w con el gradiente\n",
    "            de la función de costo respecto a w, y db es la derivada de la\n",
    "            funcion de costo respecto a b\n",
    "\n",
    "    \"\"\"\n",
    "    error = y - (x @ w + b)\n",
    "\n",
    "    # --aqui hay que poner código--        \n",
    "    dw = None\n",
    "    db = None\n",
    "    #------------------------------\n",
    "\n",
    "    return dw, db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_gradiente_lotes(x, y, w_0, b_0, nu, max_epoch):\n",
    "    \"\"\"\n",
    "    Descenso de gradiente durante num_iter iteraciones para regresión lineal\n",
    "    \n",
    "    Parámetros\n",
    "    -----------\n",
    "    x: ndarray de dimension [M, n] con los datos de entrada\n",
    "    y: ndarray de dimension [M,] con los datos de salida\n",
    "    w_0: ndarray de dimension [n, ] con los pesos iniciales\n",
    "    b_0: flotante con el sesgo inicial\n",
    "    nu: flotante con tamaño de paso o tasa de aprendizaje.\n",
    "    max_epoch: numero de iteraciones (entero)\n",
    "    \n",
    "    Devuelve\n",
    "    --------\n",
    "    w, b, mse_iter: donde w y b tiene las dimensiones de w_0 y b_0 con los parámetros \n",
    "                    aprendidos, mientras que mse_hist es un ndarray de dimensión \n",
    "                    [num_iter, 1] con el costo en cada iteración.\n",
    "    \n",
    "    \"\"\"\n",
    "    w, b = w_0.copy(), b_0\n",
    "    mse_iter = np.zeros(max_epoch)    \n",
    "    M, n = x.shape\n",
    "    \n",
    "    for iter in range(max_epoch):\n",
    "        \n",
    "        dw, db = grad_costo(x, y, w, b)\n",
    "        \n",
    "        # --aqui hay que poner código--        \n",
    "        w -= None\n",
    "        b -= None    \n",
    "        #------------------------------\n",
    "        \n",
    "        mse_iter[iter] = mse(x, y, w, b)\n",
    "\n",
    "    return w, b, mse_iter\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y para saber si el algoritmo se programo bien, se puede probar en el problema del *food truck* y revisar si el valor de la función de pérdida se va reduciendo hasta estabilizarse en un mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0 = np.zeros((n,))\n",
    "b_0 = 0.0\n",
    "\n",
    "iteraciones = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "w, b, mse_historial = descenso_gradiente_lotes(x, y, w_0, b_0, alpha, iteraciones)\n",
    "\n",
    "\n",
    "plt.plot(mse_historial, 'b')\n",
    "plt.title(u'MSE por iteración')\n",
    "plt.xlabel(u'iteración')\n",
    "plt.ylabel(r'$Loss(\\omega, b)$')\n",
    "plt.figtext(x=.6, y=.6, s=\"Al final de las iteraciones:\\n\\n w1 = {}\\n b    = {}\".format(w[0], b))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a revisar virtualmente si la estimación es una linea recta que pasa entre todos los puntos.\n",
    "\n",
    "**Completa los pasos para realizar la estimación.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_estimar = np.array([[4],[24]])\n",
    "\n",
    "#\n",
    "# Agrega el codigo necesario\n",
    "#\n",
    "# y_estimado = --aquí hay que poner código--\n",
    "\n",
    "print(\"Los valores estimados son: {}\".format(y_estimado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si los valores que obtuviste son cercanos a 1 (10000 dolares) y 24.3 (243000 dolares) entonces estamos en los valores esperados. Ahora vamos a usar estos valores para graficar los datos reales y la estimación realizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[:], y, 'xr')\n",
    "plt.plot(x_estimar[:,0], y_estimado, '-b')\n",
    "plt.title(u'Ganancias anuales de una carreta de acuerso al tamaño de una ciudad')\n",
    "plt.xlabel(r\"Poblaci$\\'o$n ($\\times 10^4$ habitantes)\")\n",
    "plt.ylabel(r'Beneficios ($\\times 10^4$ dolares)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡Felicidades!** Acabas de terminar el algoritmo de aprendizaje más usado en el mundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Un ejemplo en multiples dimensiones\n",
    "\n",
    "Como el algortimo realizado ya funciona para muchas dimensiones, no se espera tener mucho problema para utilizarlos. Así que ahora vamos a cargar datos y vamos a graficar la salida respecto a dos variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/mcd-unison/aaa-curso/raw/main/ejemplos/casas_portland.txt\"\n",
    "datos = np.loadtxt(url, comments='%', delimiter=',')\n",
    "x, y = datos[:, :-1], datos[:,-1] \n",
    "\n",
    "# M es el número de instancias y n el de atributos\n",
    "M, n = x.shape\n",
    "\n",
    "plt.plot(x[:,0], y, 'rx')\n",
    "plt.title(u'Costo de una casa en relación a su tamaño')\n",
    "plt.xlabel(u\"tamaño (pies cuadrados)\")\n",
    "plt.ylabel('costo ')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x[:,1], y, 'rx')\n",
    "plt.title(u'Costo de una casa en relación al número de cuartos')\n",
    "plt.xlabel(\"cuartos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de realizar el aprendizaje podemos ver que mientras una de las variables se mide en miles de pies cuadrados, la otra variable tiene valores de 1 a 4. Esto es un problema para el algoritmo del descenso de gradiente, por lo que es necesario normalizar los datos (solo para este algoritmo) y que funcione de manera correcta. \n",
    "\n",
    "Para normalizar requerimos de dos pasos, por un lado, obtener los valores de medias y desviaciones estandares por atributo, y en segundo lugar, realizar la normalización. Los valores de medias y desviaciones estandares hay que guardarlos, ya que serán necesarios para poder normalizar los datos que se quiera estimar.\n",
    "\n",
    "**Estas funciones ya las hicimos realizadas pero revisalas por favor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtiene_medias_desviaciones(x):\n",
    "    \"\"\"\n",
    "    Obtiene las medias y las desviaciones estandar atributo a atributo.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    x: un ndarray de dimensión (T, n) donde T es el númro de elementos y \n",
    "       n el número de atributos\n",
    "    \n",
    "    Devuelve\n",
    "    ---------\n",
    "    medias, desviaciones: donde ambos son ndarrays de dimensiones (n,) con \n",
    "                          las medias y las desviaciones estandar respectivamente.\n",
    "    \n",
    "    \"\"\"\n",
    "    medias = x.mean(axis = 0)\n",
    "    desviaciones = x.std(axis = 0)\n",
    "    return medias, desviaciones\n",
    "\n",
    "    \n",
    "def normaliza(x, medias, desviaciones):\n",
    "    \"\"\"\n",
    "    Normaliza los datos x\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    x: un ndarray de dimensión (T, n) donde T es el númro de elementos y n el número de atributos\n",
    "    medias: ndarray de dimensiones (n,) con las medias con las que se normalizará\n",
    "    desviaciones: ndarray de dimensiones (n,) con las desviaciones con las que se normalizará\n",
    "    \n",
    "    Devuelve\n",
    "    --------\n",
    "    x_norm, un ndarray de las mismas dimensiones de x pero normalizado\n",
    "    \n",
    "    \"\"\"\n",
    "    return (x - medias) / desviaciones\n",
    "        \n",
    "\n",
    "# Y ahora vamos a hacer algo muy simple para probar, que pueden corroborar con el uso de una calculadora común.\n",
    "x_prueba = np.array([[1, 300],\n",
    "                    [3, 100],\n",
    "                    [2, 400],\n",
    "                    [4, 200]])\n",
    "m, d = obtiene_medias_desviaciones(x_prueba)\n",
    "\n",
    "print(\"Los datos son: \\n{}\".format(x_prueba))\n",
    "print(\"Las medias son: \\n{}\".format(m))\n",
    "print(\"Las desviaciones son: \\n{}\".format(d))\n",
    "print(\"Los datos normalizados son: \\n{}\".format(normaliza(x_prueba, m, d)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, entonces ya podemos hacer descenso de gradiente, o casi. El problema es que no sabemos cual sería el mejor valor para $\\alpha$. Escoge el valor de $\\alpha$ realizando una gráfica de 50 iteraciones solamente para valores desde 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, ... y decide cual de los valores es el que más te conviene.\n",
    "\n",
    "**Selecciona un valor, especifica aquí cual es, y justifica porque lo seleccionaste.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias, desviaciones = obtiene_medias_desviaciones(x)\n",
    "x_norm = normaliza(x, medias, desviaciones)\n",
    "\n",
    "w_ini = np.zeros((n,))\n",
    "b_ini = 0\n",
    "num_iters = 5\n",
    "\n",
    "#lpha = 0.0001  # Aqui es donde hay que hacer las pruebas\n",
    "alpha = 1\n",
    "\n",
    "_, _, mse_hist = descenso_gradiente_lotes(x_norm, y, w_ini, b_ini, alpha, num_iters)\n",
    "\n",
    "plt.plot(mse_hist, '-b')\n",
    "plt.title(r\"La curva de aprendizaje para $\\alpha =$ \" + str(alpha))\n",
    "plt.xlabel('iteraciones')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilizando las iteraciones necesarias, encuentra el valor de $\\omega$ y $b$ utilizando el descenso de gradiente.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = None\n",
    "\n",
    "alpha = None\n",
    "\n",
    "w, b, mse_hist = descenso_gradiente_lotes(x_norm, y, w_ini, b_ini, alpha, num_iters)\n",
    "\n",
    "plt.title(r\"La Curva de Aprendizaje para $\\alpha =$ \" + str(alpha))\n",
    "plt.plot(mse_hist, '-b')\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('MSE')\n",
    "plt.figtext(x = 0.6, y = 0.6, s = \"w ={}\\n b ={}\".format(w[0], b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obten el valor de una casa de 1650 pies cuadrados y 3 recamaras con el modelo obtenido (recuerda que hay que normalizar).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí el código\n",
    "x = None\n",
    "x_norm = None\n",
    "\n",
    "y_est = None\n",
    "\n",
    "print(\"Precio Estimado: \", y_est)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
