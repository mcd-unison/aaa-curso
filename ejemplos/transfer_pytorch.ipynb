{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![](https://mcd.unison.mx/wp-content/themes/awaken/img/logo_mcd.png)\n",
        "\n",
        "# Transferencia de aprendizaje simple con `pyTorch`\n",
        "\n",
        "## Aprendizaje Automático Aplicado\n",
        "\n",
        "### Maestría en Ciencia de Datos\n",
        "\n",
        "#### **Julio Waissman**, 2024\n",
        "\n",
        "[**Abrir en google Colab**](https://colab.research.google.com/github/mcd-unison/aaa-curso/blob/main/ejemplos/transfer_pytorch.ipynb)\n",
        "\n",
        "\n",
        "*Tomado de [este tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)*\n",
        "\n",
        "\n",
        "En la practica casi nadie inicia aprendiendo un modelo desde cero, ya que lo normal no es contar con un conjunto de datos de entrenamiento lo suficientemente grande o contar con la infraestructura necesaria para entrenar dichos modelos. Para más información sobre transferencia del aprendizaje puedes ver [esta presentacioncita](https://github.com/mcd-unison/aaa-curso/raw/main/slides/transfer_learning.pdf)\n",
        "\n",
        "En su lugar, lo normal es descargar algún modelo preentrenado (hay unos muy famosos), la mayoría entrenados con el conjunto de imágenes [ImageNet](https://www.image-net.org). Los dos escenarios que vamos a ver en esta libreta y son los más comunes para transferencia del aprendizaje son:\n",
        "\n",
        "1. **Ajuste fino (finetuning)**. El lugar de inicializar en forma aleatorio, usamos una red preentrenada como inicializador, y luego entrenamos todos los parámetros, aunque con una tasa de aprendizaje muy pequeña.\n",
        "\n",
        "2. **CNN preentrenada como un generador de características**. Vamos a congelar todos los pesas de todas las capas de una red preentrenada, y vamos a sustitur la última capa. Así, nuestra red en realidad es un perceptron, y el resto es un modelo fijo de extracción de caracteríaticas. Esto claramente se puede hacer con varias capas."
      ],
      "metadata": {
        "id": "f-3Wb25aLKTp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ioqf-ZUfJb12"
      },
      "outputs": [],
      "source": [
        "#Las librarias que se necesitan\n",
        "\n",
        "# Las de siempre\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "# Torch para vision (con modelos)\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "\n",
        "# Para manipular imágenes\n",
        "from PIL import Image\n",
        "\n",
        "# Para el aprendizaje\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "# Usamos GPU (poner un entorno de jecución adecuado)\n",
        "cudnn.benchmark = True\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargando datos\n",
        "\n",
        "Vamos a usar el conjunto"
      ],
      "metadata": {
        "id": "lloKo2XWQQZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargamos los datos\n",
        "%%capture\n",
        "!curl -O https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "!unzip -y hymenoptera_data.zip"
      ],
      "metadata": {
        "id": "-KqRp6QASvWN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aumento de imágenes y normalización para entrenamiento\n",
        "# Normalización para clasificación\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "# Generamos los dataset de entrenamiento y prueba\n",
        "# a partir de datos que tenemos en archivos\n",
        "data_dir = 'hymenoptera_data'\n",
        "image_datasets = {\n",
        "    x: datasets.ImageFolder(\n",
        "        os.path.join(data_dir, x),\n",
        "        data_transforms[x]\n",
        "    )\n",
        "    for x in ['train', 'val']\n",
        "}\n",
        "\n",
        "# Generamos los DataLoaders\n",
        "# a partir de los dataset\n",
        "dataloaders = {\n",
        "    x: torch.utils.data.DataLoader(\n",
        "        image_datasets[x],\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=4\n",
        "    )\n",
        "    for x in ['train', 'val']\n",
        "}\n",
        "\n",
        "# Tamaño de cada conjunto de datos\n",
        "dataset_sizes = {\n",
        "    x: len(image_datasets[x]) for x in ['train', 'val']\n",
        "}\n",
        "\n",
        "# Nombres de las clases (un problema de clasificación binaria)\n",
        "class_names = image_datasets['train'].classes"
      ],
      "metadata": {
        "id": "E-3Qld9oQ28O"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a ver algunas de las imágenes para ilustrar el *Image augmentation* y como funciona."
      ],
      "metadata": {
        "id": "5Vv571vfVgxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "\n",
        "    # Ordena los ejes como pide plt.imshow\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    # Desnormaliza la imagen normalizada\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "\n",
        "    # Despliega la imagen concatenada\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "metadata": {
        "id": "xf49kIpUWGqW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Un minibatch\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Un grid para visualizar las imágenes\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "#Mostrando las imágenes\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "metadata": {
        "id": "W3jN6EPQWVVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Funciones de entrenamiento\n",
        "\n",
        "Vamos a poner la función de entrenamiento que vamos a llamar. Esto se puede reutilizar en otros problenas con `pyTorch`, y es un poco demasiado a pié si ya estás acostumbrado a usar [Keras](https://keras.io/).\n",
        "\n",
        "Vamos a poner una funcionzota que haga todo el aprendizaje y otra para visualizar las predicciones una vez que el modelo esté entrenado."
      ],
      "metadata": {
        "id": "ePNfER5HXg7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    \"\"\"\n",
        "    Entrenamiento de la red, con entrenamiento y validación\n",
        "\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    # Directorio temporal para guardar checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Cada epoch va a terne un paso de entrenamiento y uno de validación\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()\n",
        "                else:\n",
        "                    model.eval()\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Por cada minibatch (de entrenamiento y luego de validación)\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # gradientes a zero primero\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # Solo calculamos gradientes en entrenamiento\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # Si entrenamiento paso de optimización cada minibatch\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                # Al final del epoch completo,\n",
        "                # usa un método de degeneración de peso (scheduler)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                # statistics\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # Si el modelo es mejor al del checkpoint, actualiza el checkpoint\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ],
      "metadata": {
        "id": "THEEgencYSqL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    \"\"\"\n",
        "    Hace la preducción de num_images del conjunto de validación\n",
        "    y lo despliega para ver como realiza la clasificación\n",
        "\n",
        "    La predicción la hace en gpu, pero la vosualización\n",
        "    la pasa a cpu para ahorrar recursos\n",
        "\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "XN2N2hzwauY7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Ejemplo de ajuste fino\n",
        "\n",
        "Vamos a utilizar un modelo y un conjunto de pesos preentrenados disponibles con [`torchvision`](https://pytorch.org/vision/stable/index.html). Los modelos disponibles (por default), se pueden encontrar [en este enlace](https://pytorch.org/vision/stable/models.html).\n",
        "\n",
        "Para este ejemplo vamos a usar un modelo relativamente simple, [ResNet18](https://arxiv.org/abs/1512.03385), y los datos preentrenados son [`IMAGENET1K_V1`](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.ResNet18_Weights). Se va a cargar entonces un archivo con:\n",
        "\n",
        "- 44.7 MB de tamaño\n",
        "- 11,689,512 parámetros entrenados\n",
        "\n",
        "Vamos a cargar el modelo y establecer el criterio (función de pérdida) optimizador y calendarizador (para la degeneración de la tasa de aprendizaje)"
      ],
      "metadata": {
        "id": "rq8NZEncbYND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos resnet18\n",
        "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Obtenemos cuantas entradas tiene la capa final\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "# Sustituimos la capa final por un clasificador binario\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Mandamos el modelo al GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# La funcion de pérdida clásica (con logits)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Todos los parámetros se van a optimizar\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Degeneración de la tasa de aprendizaje en 0.1 cada 7 epoch\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "ngQj89xMco3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y ahora si a entrenar. Toma de 15 a 25 minutos en CPU y menos de un minuto en GPU aproximadamente y dependiendo del humor de `colab`"
      ],
      "metadata": {
        "id": "LwT0U4CMfCO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(\n",
        "    model_ft,\n",
        "    criterion,\n",
        "    optimizer_ft,\n",
        "    exp_lr_scheduler,\n",
        "    num_epochs=25\n",
        ")"
      ],
      "metadata": {
        "id": "LTls3nkafOsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y vamos a visualizar que tal"
      ],
      "metadata": {
        "id": "lceJcA4yfz3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model_ft)"
      ],
      "metadata": {
        "id": "AgbH-0K5f3RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Ejemplo como generador de características\n",
        "\n",
        "Aqui vamos a congelar todos los parámetros, salvo los de la última capa (que es la única que cambiamos en la arquitectura, por cierto.\n",
        "\n",
        "Así que va a ser muy similar al ajuste fino, solamente que vamos a poner como `requires_grad = False`a todos los parámetros que no sean de la última capa."
      ],
      "metadata": {
        "id": "bJy5HFASgEjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga el modelo y los parámetros preentrenados\n",
        "model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Pone todos los parámetros como no entrenables\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Cambia la última capa.\n",
        "# Cuando hay nuevos parámetros, estos son entrenables por default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Pasa el modelo al GPU\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "# Criterio de pérdida\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizador, solo se ponen los parámetros de la última capa\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Reduce la tasa de aprendizaje en 0.1 cada 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "wlerpT1Bgqro"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En CPU tarda menos de la mitad de tiempo que el ajuste de todos los parámetros y los resultados parecen mejores."
      ],
      "metadata": {
        "id": "haRjmH3FhyND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = train_model(\n",
        "    model_conv,\n",
        "    criterion,\n",
        "    optimizer_conv,\n",
        "    exp_lr_scheduler,\n",
        "    num_epochs=25\n",
        ")"
      ],
      "metadata": {
        "id": "BBfFjid1hdJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model_conv)"
      ],
      "metadata": {
        "id": "oDhyH1Nlh_Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Usando el modelo entrenado\n",
        "\n",
        "Vamos a hacer una funcioncita para poder usarlo con una imagen cualquiera"
      ],
      "metadata": {
        "id": "dlKX6igciY_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model_predictions(model, img_path):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    # Vamos a cargar y transformar la imagen\n",
        "    # Usamos las transformaciones definidas para validación\n",
        "    img = Image.open(img_path)\n",
        "    img = data_transforms['val'](img)\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.to(device)\n",
        "\n",
        "    # Realiza la predicción y despliega el resultado\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        ax = plt.subplot(2,2,1)\n",
        "        ax.axis('off')\n",
        "        ax.set_title(f'Predicted: {class_names[preds[0]]}')\n",
        "        imshow(img.cpu().data[0])\n",
        "\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "WYvvF4mpikQA"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model_predictions(\n",
        "    model_conv,\n",
        "    img_path='hymenoptera_data/val/bees/72100438_73de9f17af.jpg'\n",
        ")"
      ],
      "metadata": {
        "id": "nzioNG5oi84P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}