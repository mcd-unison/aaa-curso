---
title: Modelos lineales y redes densas 
subtitle: Curso Aprendizaje Automático Aplicado
layout: page
hero_image: https://github.com/mcd-unison/aaa-curso/raw/main/docs/img/intro-banner.jpeg
hero_darken: true
show_sidebar: false
---

## Mas allá de la regresión lineal

1. [Presentación sobre generación de características (del curso de IA de Stanford)](https://github.com/IA-UNISON/material/raw/master/presentaciones/non-linear-features.pdf)

2. [Una presentación sobre las nociones básicas de redes neuronales](https://github.com/mcd-unison/aaa-curso/raw/main/slides/neural-networks.pdf) así como el [importante algoritmo de *backpropagation*](https://github.com/mcd-unison/aaa-curso/raw/main/slides/backpropagation.pdf). También un [video muy bueno](https://www.youtube.com/watch?v=eNIqz_noix8&t=1s) sobre *b-prop* hecho por *Dot CSV* un youtuber muy recomendable que habla sobre redes neuronales profundas.

## Modelos lineales generativos

1. Naive bayes. [Una presentación de CMU](https://www.cs.cmu.edu/~10601b/slides/NBayes.pdf) y [otra de NYU, MIT-CSAIL](https://people.csail.mit.edu/dsontag/courses/ml12/slides/lecture17.pdf). 


## Maquinas de vectores de soporte

1. [Una presentación bien viejita](https://github.com/mcd-unison/aaa-curso/raw/main/slides/svm_presentacion.pdf) pero que sigue estando decente.

2. Un tutorial muy completo sobre la teoría y los algoritmos de [regresión con máquinas de vectores de soporte](https://alex.smola.org/papers/2004/SmoSch04.pdf).

3. Unas libretas de ejemplo para ejecutar en Kaggle. Un [tutorial de SVM para clasificación](https://www.kaggle.com/prashant111/svm-classifier-tutorial), [otro de múltiples clases, usando búsqueda exhaustiva sobre los valores de los parámetros](https://www.kaggle.com/pranathichunduru/svm-for-multiclass-classification/notebook). Por último [otro tutorial](https://www.kaggle.com/faressayah/support-vector-machine-pca-tutorial-for-beginner/notebook) que usa algunas de las bases de datos más usadas en los tutoriales y cursos de aprendizaje automático.


## Libretas *jupyter*

1. [Una libreta sobre naive Bayes](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.05-Naive-Bayes.ipynb).

2. [Un libreta sobre regresión lineal](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.06-Linear-Regression.ipynb)

3. [Una libreta de máquinas de vectores de soporte](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.07-Support-Vector-Machines.ipynb)

4. [Un ejemplito de redes neuronales en pyTorch](https://colab.research.google.com/github/mcd-unison/aaa-curso/blob/main/ejemplos/pytorch_ejemplo_simple.ipynb).




