---
title: Teoría del aprendizaje supervisado 
subtitle: Curso Aprendizaje Automático Aplicado
layout: page
hero_image: https://github.com/mcd-unison/aaa-curso/raw/main/docs/img/intro-banner.jpeg
hero_darken: true
show_sidebar: false
---


## Presentaciones

1. [¿Qué es el aprendizaje supervisado?](https://github.com/mcd-unison/aaa-curso/raw/main/slides/intro-supervisado.pdf)

2. [¿En que sentido el aprendizaje supervisado es posible?](https://github.com/mcd-unison/aaa-curso/raw/main/slides/generalizacion.pdf).

4. [Mi primer modelo de aprendizaje](https://github.com/mcd-unison/aaa-curso/raw/main/slides/ejemplo_modelo.pdf) 


5. ¿Y porque esas funciones, y esas funciones de costo? [Una presentación sobre GLM](https://github.com/mcd-unison/aaa-curso/raw/main/slides/glm.pdf)

6. [Documento sobre GLM](https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf) del curso de Andrew Ng de Stanford.

7. La página de wikipedia de [la familia exponencial de distribuciones de probabilidad](https://en.wikipedia.org/wiki/Exponential_family).

8. [Una presentación sobre métricas](https://github.com/mcd-unison/aaa-curso/raw/main/slides/metricas.pdf) o como saber si mi modelo está bien usando diferentes métricas como [coeficiente de determinación](https://en.wikipedia.org/wiki/Coefficient_of_determination), [matrices de confusión](https://en.wikipedia.org/wiki/Confusion_matrix) o [la curva ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)

8. [Presentación sobre validación](http://www.cs.rpi.edu/~magdon/courses/LFD-Slides/SlidesLect13.pdf) de [M. Magdon-Ismail](http://www.cs.rpi.edu/~magdon/)

9.  [Introducción a las MLOps](https://github.com/mcd-unison/aaa-curso/raw/main/slides/mlflow_recortes.pdf)


5. [Presentación sobre generación de características (del curso de IA de Stanford)](https://github.com/IA-UNISON/material/raw/master/presentaciones/non-linear-features.pdf)

1. [Una presentación sobre las nociones básicas de redes neuronales](https://github.com/mcd-unison/aaa-curso/raw/main/slides/neural-networks.pdf) así como el [importante algoritmo de *backpropagation*](https://github.com/mcd-unison/aaa-curso/raw/main/slides/backpropagation.pdf). También un [video muy bueno](https://www.youtube.com/watch?v=eNIqz_noix8&t=1s) sobre *b-prop* hecho por *Dot CSV* un youtuber muy recomendable que habla sobre redes neuronales profundas.


6. [Presentación sobre el *overfiting*](http://www.cs.rpi.edu/~magdon/courses/LFD-Slides/SlidesLect11.pdf) de [M. Magdon-Ismail](http://www.cs.rpi.edu/~magdon/)

7. [Presentación sobre regularización](http://www.cs.rpi.edu/~magdon/courses/LFD-Slides/SlidesLect12.pdf) de [M. Magdon-Ismail](http://www.cs.rpi.edu/~magdon/)

8. [Presentación sobre validación](http://www.cs.rpi.edu/~magdon/courses/LFD-Slides/SlidesLect13.pdf) de [M. Magdon-Ismail](http://www.cs.rpi.edu/~magdon/)

9.  [Introducción a las MLOps](https://github.com/mcd-unison/aaa-curso/raw/main/slides/MLOps-intro.pdf)


## Libretas *jupyter*

1. [Un ejemplito de la heurística de la dimensión VC](https://github.com/mcd-unison/aaa-curso/blob/main/ejemplos/evolucion_dvc.ipynb)

2. [Comparación de modelos de clasificación](https://colab.research.google.com/github/mcd-unison/aaa-curso/blob/main/ejemplos/plot_classifier_comparison.ipynb)

3. [Un ejemplito de redes neuronales en pyTorch](https://colab.research.google.com/github/mcd-unison/aaa-curso/blob/main/ejemplos/pytorch_ejemplo_simple.ipynb).

4. [Un libreta sobre regresión lineal copn regularización](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.06-Linear-Regression.ipynb)
