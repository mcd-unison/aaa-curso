---
title: Redes Neuronales 
subtitle: Curso Aprendizaje Automático Aplicado
layout: page
hero_image: https://github.com/mcd-unison/aaa-curso/raw/main/docs/img/intro-banner.jpeg
hero_darken: true
show_sidebar: false
---

## Recursos generales y de consulta

1. El libro [Deep Learning](https://www.deeplearningbook.org) de Ian Goodfellow, Yoshua Bengio y Aaron Courville gratuito en linea con material adicional.

2. Un [excelente curso](http://introtodeeplearning.com) de introducción al aprendizaje profundo del MIT con videos. transparencias y código.

3. No se puede vivir y hacer *deep learning* si no utilizamos regularmente el sitio de [*papers with code*](https://paperswithcode.com). Código, tutriales, onjuntos de datos, modelos preentrenados,...

4. [NeurIPS](https://nips.cc), la conferencia más importante en redes neuronales y en general en aprendizaje automñatico.

5. [Journal of Machine Learning Research](https://jmlr.org) es una publicación libre muy completa sobre el último grito de la moda en ML. Muy buenos artículos, pero ya bastante más densos que en los otros recursos listados. 

6. Para usar transformadores, uno de los lugares con los mejores modelos preentrenados es la compañía [*Hugging Face*](https://huggingface.co). Muchos recursos en código abierto.

7. Otras compañías con recursos en código abierto, modelos preentrenados, librerías y *frameworks* que vale la pena estar revisando son [OpenAI](https://openai.com) (cada vez menos abierta y cada vez más *for profit*), [Meta AI](https://ai.facebook.com), ahora ya con licencias tipo MIT, y [Google Research](https://research.google).

8. [Un listado de conjuntos de datos](https://datasets.activeloop.ai/docs/ml/datasets/)n que se utilizan muy intensivamente en tareas de aprendizaje profundo. 

## Redes neuronales: nociones básicas 

1. [Una presentación sobre las nociones básicas de redes neuronales](https://github.com/mcd-unison/aaa-curso/raw/main/slides/neural-networks.pdf) así como el [importante algoritmo de *backpropagation*](https://github.com/mcd-unison/aaa-curso/raw/main/slides/backpropagation.pdf). Tambien un [video muy bueno](https://www.youtube.com/watch?v=eNIqz_noix8&t=1s) sobre +b-prop* hecho por *Dot CSV* un youtuber muy recomendable que habla sobre redes neuronales profundas.
   
2. [*An overview of gradient descent optimization algorithms*](https://www.ruder.io/optimizing-gradient-descent/) de Sebastian Ruder.
   
3. [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/) por Andrej Karpathy.
   

## Redes Convolucionales

1. Una presentación sobre [redes convolucionales](https://github.com/mcd-unison/aaa-curso/raw/main/slides/convolucionales.pdf).

2. Una [muy buena presentación del curso del MIT](http://introtodeeplearning.com/slides/6S191_MIT_DeepLearning_L3.pdf) sobre CNN para visión por computadora, así como [un ejercicio en colab de *autocodificadores variacionales*](https://colab.research.google.com/github/aamini/introtodeeplearning/blob/2023/lab2/Part2_FaceDetection.ipynb), basado en [éste artículo de ellos mismos](http://introtodeeplearning.com/AAAI_MitigatingAlgorithmicBias.pdf).

3. Una presentación sobre [transferencia del aprendizaje](https://github.com/mcd-unison/aaa-curso/raw/main/slides/transfer_learning.pptx) (tambien [en pdf](https://github.com/mcd-unison/aaa-curso/raw/main/slides/transfer_learning.pdf)).

4. Un [recurso](https://arxiv.org/abs/2303.17580) que vale la pena darle una ojeada y ver que se puede replicar. Aquí [la liga a el sistema](https://huggingface.co/spaces/microsoft/HuggingGPT), solo se necesita estar registrado en *OpenAI* y en *HF Spaces*.

## Algunas libretas con ejemplos

1. [Una libreta en colab](https://colab.research.google.com/github/aamini/introtodeeplearning/blob/master/lab1/Part1_TensorFlow.ipynb) de introducción a Tensorflow, de un curso del MIT.

2. [Una libreta para jugar con modelos pre-entrenados de TensorFlow Hub](https://colab.research.google.com/github/mcd-unison/aaa-curso/blob/main/ejemplos/transfer.ipynb)


## Aprendizaje auto-supervisado (*Self supervised learning)

1. [Una presentación reciente muy orientada a visión](https://github.com/mcd-unison/aaa-curso/raw/main/slides/ssl-Johnson-22.pdf) por [Justin Johnson](https://web.eecs.umich.edu/~justincj/) de U. Mich.

2. [Otra presentación](https://github.com/mcd-unison/aaa-curso/raw/main/slides/ssl-Wang-19.pdf) por [Naiyan Wang](https://winsty.net). Las dos son bastante claras en las ideas sin ir al detalle.

3. [Word Embeddings (Algorithms for NLP)](http://demo.clab.cs.cmu.edu/11711fa18/slides/FA18%2011-711%20lecture%206%20--%20Word%20Embeddings%202.pdf)

4. ¿Porque es tan importante el aprendizaje autosupervisado en NLP? Leer el artículo [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)
   
5. Una entrada de blog muy interesante de Yann LeCun: [*Self-supervised learning: The dark matter of intelligence*](https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/)

6. [Otra presentación muy extensa](https://github.com/mcd-unison/aaa-curso/raw/main/slides/ssl-Vakanski-20.pdf) de [Alex Vakanski](https://www.uidaho.edu/engr/our-people/alex-vakanski). Solo si les interesa mucho el tema y se quieren mirar toda la presentación (básicamente lo mismo que la presentación 1 pero con lujo de detalle).

