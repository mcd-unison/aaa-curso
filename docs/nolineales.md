---
title: Modelos no lineales de aprendizaje 
subtitle: Curso Aprendizaje Automático Aplicado
layout: page
hero_image: https://github.com/mcd-unison/aaa-curso/raw/main/docs/img/intro-banner.jpeg
hero_darken: true
show_sidebar: false
---


## Árboles de decisión

1. [Presentación](https://people.csail.mit.edu/dsontag/courses/ml16/slides/lecture11.pdf) de David Sontag (NYU) sobre árboles de decisión y bosques aleatorios.

2. [Un reporte de Quinlan](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.4267&rep=rep1&type=pdf) de 1986 con algunas técnicas para reducir el error en árboles de decisión usando *post-poda*.

## Modelos de *ensemble*

1. [Presentación](https://scholar.princeton.edu/sites/default/files/bstewart/files/boosting.pdf) de J. Cohen (Princeton) sobre *boosting*, que cubre los métodos de *Adaboost* y *Gradient boosting trees*. Para el algoritmo de *Gradient Boostong* aqui dejamos una [presentación](https://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf) más clara de las ideas originales.

2. La librería [XGboost](https://xgboost.readthedocs.io/en/stable/), la más utilizada para *Gradient Boosting*.

3. Una [presentación](https://www.cs.ubc.ca/~lowe/425/slides/13-ViolaJones.pdf) del famoso algoritmo de Viola-Jones, y una [presentación](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2a[…]a-Jones%2520presentation.ppt&usg=AOvVaw0XtfrKMk_OnA9HawvyZ6vI) hecha por los autores del algoritmo.
   
## Otros modelos de aprendizaje

1. K Vecinos próximos. [Una presentación de D. Sontag de la NYU](https://github.com/mcd-unison/aaa-curso/raw/main/slides/knn-ny.pdf) y [otra presentación de M Kang de la UNLV](https://mkang.faculty.unlv.edu/teaching/CS489_689/05.KNN.pdf)